import torch
import torch.nn as nn
import onnx
import sys
import os

# ãƒ‘ã‚¹è¨­å®š (ç’°å¢ƒã«åˆã‚ã›ã¦æ›¸ãæ›ãˆã¦ãã ã•ã„)
sys.path.append(".") 

# å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# â€»ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã‚’ç¢ºèªã—ã¦ä¿®æ­£ã—ã¦ãã ã•ã„
try:
    from models.modules.net_module.styleunet import StyleUNet
    from models.modules.net_module.feature_decoder import Vertex_GS_Decoder
    # DINO Encoderã¯å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¾å­˜ãŒæ¿€ã—ã„ã®ã§ã€ä»Šå›ã¯Refinerã¨Decoderã‚’å„ªå…ˆã—ã¾ã™
    print("âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®šç¾©ã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸ")
except ImportError as e:
    print(f"âŒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’GUAVAãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ«ãƒ¼ãƒˆã«ç½®ã„ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    exit()

# ------------------------------------------------------------------
# 1. é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
# ------------------------------------------------------------------
WEIGHTS_PATH = "best_160000.pt"

if not os.path.exists(WEIGHTS_PATH):
    print(f"âŒ '{WEIGHTS_PATH}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    print("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸ .pt ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜å ´æ‰€ã«ç½®ã„ã¦ãã ã•ã„ã€‚")
    exit()

print(f"ğŸ“‚ é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {WEIGHTS_PATH} (1.2GBã‚ã‚‹ã®ã§æ™‚é–“ã‹ã‹ã‚Šã¾ã™...)")
checkpoint = torch.load(WEIGHTS_PATH, map_location="cpu")

# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ§‹é€ ã‚’ç¢ºèª
state_dict = checkpoint
if 'state_dict' in checkpoint:
    state_dict = checkpoint['state_dict']
elif 'model' in checkpoint:
    state_dict = checkpoint['model']

print("âœ… é‡ã¿ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚ã‚­ãƒ¼ã®æ•°:", len(state_dict))

# ------------------------------------------------------------------
# 2. Neural Refiner (StyleUNet + MLP) ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# ------------------------------------------------------------------
print("\nğŸš€ [1/2] Neural Refiner (CompleteRefiner) ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ...")

class CompleteRefiner(nn.Module):
    def __init__(self, id_dim=256, style_dim=512):
        super().__init__()
        # ubody_gaussian.py ã®æ§‹é€ ã‚’å†ç¾
        self.id_mlp = nn.Sequential(
            nn.Linear(id_dim, style_dim),
            nn.ReLU(inplace=True),
            nn.Linear(style_dim, style_dim),
            nn.ReLU(inplace=True),
            nn.Linear(style_dim, style_dim),
        )
        self.rgb_decoder = StyleUNet(
            in_size=512, out_size=512, in_dim=32, out_dim=3, num_style_feat=512
        )

    def forward(self, feature_map, id_embedding):
        style = self.id_mlp(id_embedding)
        return self.rgb_decoder(feature_map, style)

refiner = CompleteRefiner()

# é‡ã¿ã®æŠ½å‡ºã¨ãƒ­ãƒ¼ãƒ‰
refiner_dict = {}
for k, v in state_dict.items():
    name = k.replace("module.", "")
    # ubody_gaussian.py ã§ã¯ 'rgb_decoder' ã¨ 'id_mlp' ã¨ã„ã†åå‰ã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã¯ãš
    if name.startswith("rgb_decoder") or name.startswith("id_mlp"):
        refiner_dict[name] = v

try:
    refiner.load_state_dict(refiner_dict, strict=True)
    print("âœ… Refiner Weights Verified! (Strict Mode)")
except Exception as e:
    print("âš ï¸ Refiner Strict Load Failed. Trying loose load...", e)
    refiner.load_state_dict(refiner_dict, strict=False)

refiner.eval()
dummy_fm = torch.randn(1, 32, 512, 512)
dummy_id = torch.randn(1, 256)

torch.onnx.export(
    refiner, (dummy_fm, dummy_id), "neural_refiner_complete.onnx",
    input_names=["feature_map", "id_embedding"], output_names=["rgb_image"],
    opset_version=14
)
print("ğŸ“¦ neural_refiner_complete.onnx ç”Ÿæˆå®Œäº†ï¼")


# ------------------------------------------------------------------
# 3. Template Decoder (Vertex_GS_Decoder) ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# ------------------------------------------------------------------
print("\nğŸš€ [2/2] Template Decoder ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ...")

# åˆæœŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ ubody_gaussian.py ã® __init__ ã‚’å‚ç…§
# é€šå¸¸: in_dim=1024, dir_dim=27 (harmonic=4), color_out_dim=32
# feature_decoder.py ã® Vertex_GS_Decoder ã‚’ä½¿ç”¨
decoder = Vertex_GS_Decoder(in_dim=1024, dir_dim=27, color_out_dim=32)

# é‡ã¿ã®æŠ½å‡º
decoder_dict = {}
prefix = "prj_feature_decoder." # ã¾ãŸã¯ "uv_feature_decoder"
for k, v in state_dict.items():
    name = k.replace("module.", "")
    if name.startswith(prefix):
        decoder_dict[name.replace(prefix, "")] = v

if len(decoder_dict) == 0:
    print("âš ï¸ 'prj_feature_decoder' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚'uv_feature_decoder' ã§è©¦ã—ã¾ã™ã€‚")
    prefix = "uv_feature_decoder."
    for k, v in state_dict.items():
        name = k.replace("module.", "")
        if name.startswith(prefix):
            decoder_dict[name.replace(prefix, "")] = v

try:
    decoder.load_state_dict(decoder_dict, strict=True)
    print("âœ… Decoder Weights Verified! (Strict Mode)")
except Exception as e:
    print("âš ï¸ Decoder Strict Load Failed...", e)
    decoder.load_state_dict(decoder_dict, strict=False)

decoder.eval()

# å…¥åŠ›: [Projection(128) + Base(128) + Global(256)] = 512æ¬¡å…ƒï¼Ÿ
# â€»æ³¨æ„: ubody_gaussian.py ã§ã¯ Feature Concat å¾Œã« Vertex_GS_Decoder ã«å…¥ã‚Œã¾ã™ãŒ
# Vertex_GS_Decoder ã® in_dim ãŒ 1024 ãªã®ã§ã€å…¥åŠ›æ¬¡å…ƒã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
# ã“ã“ã§ã¯ä¸€æ—¦ã€å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹é€šã‚Š 1024æ¬¡å…ƒ ã®å…¥åŠ›ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
# TypeScriptå´ã§ cat([proj, base, global, ...]) ã§ 1024 ã«ãªã‚‹ã‚ˆã†ã«èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚

dummy_feat = torch.randn(1, 10595, 1024) 
dummy_dir = torch.randn(1, 10595, 27) # view direction

torch.onnx.export(
    decoder, (dummy_feat, dummy_dir), "template_decoder.onnx",
    input_names=["fused_features", "view_dirs"], 
    output_names=["rgb", "opacity", "scale", "rotation", "offset"],
    opset_version=14
)
print("ğŸ“¦ template_decoder.onnx ç”Ÿæˆå®Œäº†ï¼")

print("\nğŸ‰ å…¨å·¥ç¨‹çµ‚äº†ã€‚ç”Ÿæˆã•ã‚ŒãŸ .onnx ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ assets ãƒ•ã‚©ãƒ«ãƒ€ã¸ï¼")