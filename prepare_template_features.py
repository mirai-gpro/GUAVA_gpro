#!/usr/bin/env python3
"""
prepare_template_features.py

Template Decoderç”¨ã®ç‰¹å¾´ã‚’äº‹å‰ã«é€£çµã—ã¦ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å…¬å¼å®Ÿè£… (ubody_gaussian.py lines 126-133):
    vertex_base_feature = self.vertex_base_feature[None].expand(batch_size, -1, -1)
    vertex_sample_feature = self.sample_prj_feature(...)
    vertex_global_feature = self.global_feature_mapping(global_feature)
    vertex_global_feature = vertex_global_feature[:,None,:].expand(-1, N, -1)
    
    # é€£çµ
    vertex_sample_feature = torch.cat([
        vertex_sample_feature,      # [B, N, 128] from projection
        vertex_base_feature,        # [B, N, 128] learnable
        vertex_global_feature       # [B, N, 256] from CLS
    ], dim=-1)  # Result: [B, N, 512]

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯:
1. vertex_base_feature.bin (å­¦ç¿’æ¸ˆã¿) [N, 128]
2. ã‚¼ãƒ­åŸ‹ã‚ã®projection placeholder [N, 128]
3. ã‚¼ãƒ­åŸ‹ã‚ã®global placeholder [N, 256]
ã‚’é€£çµã—ã¦ [N, 512] ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

å®Ÿè¡Œæ™‚ã«TypeScriptå´ã§:
- projectionéƒ¨åˆ† [0:128] ã‚’å®Ÿéš›ã®å€¤ã§ä¸Šæ›¸ã
- globaléƒ¨åˆ† [256:512] ã‚’ID embeddingã§ä¸Šæ›¸ã
"""

import numpy as np
import argparse
import os
from pathlib import Path


def load_vertex_base_feature(filepath):
    """
    vertex_base_feature.bin ã‚’ãƒ­ãƒ¼ãƒ‰
    
    Args:
        filepath: vertex_base_feature.binã®ãƒ‘ã‚¹
        
    Returns:
        numpy.ndarray: [N, 128] ã®ç‰¹å¾´
    """
    if not os.path.exists(filepath):
        print(f"âš ï¸  {filepath} not found, will use zero-filled features")
        return None
    
    data = np.fromfile(filepath, dtype=np.float32)
    
    # [N, 128] ã«reshape
    if len(data) % 128 != 0:
        raise ValueError(f"Invalid data size: {len(data)} (expected multiple of 128)")
    
    num_vertices = len(data) // 128
    features = data.reshape(num_vertices, 128)
    
    print(f"âœ… Loaded vertex_base_feature: [{num_vertices}, 128]")
    return features


def create_combined_template_features(num_vertices, base_feature=None):
    """
    Template Decoderç”¨ã®512æ¬¡å…ƒç‰¹å¾´ã‚’ç”Ÿæˆ
    
    æ§‹é€ :
        [0:128]   - Projection features (å®Ÿè¡Œæ™‚ã«ä¸Šæ›¸ã)
        [128:256] - Base features (å­¦ç¿’æ¸ˆã¿ã¾ãŸã¯ã‚¼ãƒ­åŸ‹ã‚)
        [256:512] - Global features (å®Ÿè¡Œæ™‚ã«ä¸Šæ›¸ã)
    
    Args:
        num_vertices: é ‚ç‚¹æ•° (é€šå¸¸10595)
        base_feature: Base features [N, 128] (Noneã®å ´åˆã¯ã‚¼ãƒ­åŸ‹ã‚)
        
    Returns:
        numpy.ndarray: [N, 512] ã®é€£çµç‰¹å¾´
    """
    print(f"\nğŸ”§ Creating combined features for {num_vertices} vertices...")
    
    # 1. Projection features placeholder (å®Ÿè¡Œæ™‚ã«ä¸Šæ›¸ãã•ã‚Œã‚‹)
    projection_placeholder = np.zeros((num_vertices, 128), dtype=np.float32)
    print(f"  [0:128]   Projection placeholder: {projection_placeholder.shape}")
    
    # 2. Base features (å­¦ç¿’æ¸ˆã¿ã¾ãŸã¯ã‚¼ãƒ­åŸ‹ã‚)
    if base_feature is not None and base_feature.shape[0] == num_vertices:
        base_features = base_feature
        print(f"  [128:256] Base features (loaded): {base_features.shape}")
    else:
        base_features = np.zeros((num_vertices, 128), dtype=np.float32)
        print(f"  [128:256] Base features (zero-filled): {base_features.shape}")
    
    # 3. Global features placeholder (å®Ÿè¡Œæ™‚ã«ä¸Šæ›¸ãã•ã‚Œã‚‹)
    global_placeholder = np.zeros((num_vertices, 256), dtype=np.float32)
    print(f"  [256:512] Global placeholder: {global_placeholder.shape}")
    
    # é€£çµ: [N, 128] + [N, 128] + [N, 256] = [N, 512]
    combined = np.concatenate([
        projection_placeholder,  # [0:128]
        base_features,           # [128:256]
        global_placeholder       # [256:512]
    ], axis=1)
    
    print(f"\nâœ… Combined features shape: {combined.shape}")
    print(f"   Total size: {combined.nbytes / 1024 / 1024:.2f} MB")
    
    return combined


def save_combined_features(combined, output_path):
    """
    é€£çµæ¸ˆã¿ç‰¹å¾´ã‚’ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    
    Args:
        combined: [N, 512] ã®ç‰¹å¾´
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    # Flatten to 1D
    data = combined.flatten()
    
    # Save as float32 binary
    data.tofile(output_path)
    
    print(f"\nğŸ’¾ Saved to: {output_path}")
    print(f"   File size: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")
    print(f"   Shape: [{combined.shape[0]}, 512]")
    print(f"   Data type: float32")


def verify_file(filepath, expected_vertices):
    """
    ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œè¨¼
    
    Args:
        filepath: æ¤œè¨¼ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        expected_vertices: æœŸå¾…ã•ã‚Œã‚‹é ‚ç‚¹æ•°
    """
    print(f"\nğŸ” Verifying {filepath}...")
    
    data = np.fromfile(filepath, dtype=np.float32)
    expected_size = expected_vertices * 512
    
    if len(data) != expected_size:
        print(f"âŒ Size mismatch: {len(data)} != {expected_size}")
        return False
    
    # Reshape
    features = data.reshape(expected_vertices, 512)
    
    # çµ±è¨ˆæƒ…å ±
    print(f"âœ… File is valid")
    print(f"   Shape: {features.shape}")
    print(f"   Min: {features.min():.6f}")
    print(f"   Max: {features.max():.6f}")
    print(f"   Mean: {features.mean():.6f}")
    print(f"   Non-zeros: {np.count_nonzero(features)} / {features.size}")
    
    # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ±è¨ˆ
    print(f"\n   Section stats:")
    print(f"     [0:128]   Projection: min={features[:, 0:128].min():.6f}, max={features[:, 0:128].max():.6f}")
    print(f"     [128:256] Base:       min={features[:, 128:256].min():.6f}, max={features[:, 128:256].max():.6f}")
    print(f"     [256:512] Global:     min={features[:, 256:512].min():.6f}, max={features[:, 256:512].max():.6f}")
    
    return True


def main():
    parser = argparse.ArgumentParser(
        description='Prepare combined template features for GUAVA pipeline'
    )
    parser.add_argument(
        '--base-feature',
        type=str,
        default='vertex_base_feature.bin',
        help='Path to vertex_base_feature.bin (default: vertex_base_feature.bin)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='combined_template_features.bin',
        help='Output file path (default: combined_template_features.bin)'
    )
    parser.add_argument(
        '--num-vertices',
        type=int,
        default=10595,
        help='Number of vertices (default: 10595 for SMPL-X)'
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ­ GUAVA Template Features Preparation")
    print("=" * 60)
    
    # 1. Load base features (optional)
    base_feature = None
    if os.path.exists(args.base_feature):
        base_feature = load_vertex_base_feature(args.base_feature)
        if base_feature.shape[0] != args.num_vertices:
            print(f"âš ï¸  Vertex count mismatch: {base_feature.shape[0]} != {args.num_vertices}")
            print(f"   Using zero-filled features instead")
            base_feature = None
    
    # 2. Create combined features
    combined = create_combined_template_features(args.num_vertices, base_feature)
    
    # 3. Save
    save_combined_features(combined, args.output)
    
    # 4. Verify
    verify_file(args.output, args.num_vertices)
    
    print("\n" + "=" * 60)
    print("âœ… Complete!")
    print("=" * 60)
    print(f"\nğŸ“ Next steps:")
    print(f"   1. Copy {args.output} to public/assets/")
    print(f"   2. Update TypeScript to load this file")
    print(f"   3. At runtime, overwrite:")
    print(f"      - [0:128] with projection features from image encoder")
    print(f"      - [256:512] with expanded ID embedding")
    print()


if __name__ == '__main__':
    main()
